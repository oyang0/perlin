{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11999bcc-f167-4bf7-ac25-d788dfbabced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perlin import rand_perlin_2d\n",
    "from perlin import rand_perlin_2d_octaves\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from random import uniform\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.nn.init import orthogonal_\n",
    "from torch.nn.init import constant_\n",
    "\n",
    "from torchvision.transforms import RandomCrop\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import PILToTensor\n",
    "\n",
    "to_pil_image = ToPILImage()\n",
    "to_tensor = ToTensor()\n",
    "pil_to_tensor = PILToTensor()\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf3878-4ce8-422b-b591-7418d02bcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, img_dir, ptch_sz=40, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_nms = listdir(img_dir)\n",
    "        self.cropper = RandomCrop(size=(ptch_sz, ptch_sz))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_nms)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = join(self.img_dir, self.img_nms[idx])\n",
    "        image = Image.open(img_path).convert('1')\n",
    "        image = self.cropper(image)\n",
    "        image = to_tensor(image)\n",
    "        noise = get_noise(image)\n",
    "        observation = get_observation(image, noise)\n",
    "        if self.transform:\n",
    "            observation = self.transform(observation)\n",
    "        if self.target_transform:\n",
    "            noise = self.target_transform(noise)\n",
    "        return observation, noise\n",
    "\n",
    "\n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth=17,\n",
    "        n_channels=64,\n",
    "        image_channels=1,\n",
    "        kernel_size=3,\n",
    "        padding=1,\n",
    "    ):\n",
    "        super(DnCNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                image_channels,\n",
    "                n_channels,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                stride=(1, 1),\n",
    "                padding=(padding, padding),\n",
    "                bias=True,\n",
    "            )\n",
    "        )\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(depth - 2):\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    n_channels,\n",
    "                    n_channels,\n",
    "                    kernel_size=(kernel_size, kernel_size),\n",
    "                    stride=(1, 1),\n",
    "                    padding=(padding, padding),\n",
    "                    bias=True,\n",
    "                )\n",
    "            )\n",
    "            layers.append(\n",
    "                nn.BatchNorm2d(\n",
    "                    n_channels,\n",
    "                    eps=1e-05,\n",
    "                    momentum=0.1,\n",
    "                    affine=True,\n",
    "                    track_running_stats=True,\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                n_channels,\n",
    "                image_channels,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                stride=(1, 1),\n",
    "                padding=(padding, padding),\n",
    "                bias=True,\n",
    "            )\n",
    "        )\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                orthogonal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                constant_(m.weight, 1)\n",
    "                constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class PepperWithLogitsLoss(nn.Module):\n",
    "    def __init__(self, weight=None, reduction='mean', pos_weight=None):\n",
    "        super(PepperWithLogitsLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.loss = nn.BCEWithLogitsLoss(\n",
    "            weight=weight, reduction='none', pos_weight=pos_weight\n",
    "        )\n",
    "\n",
    "    def forward(self, pred, y, X):\n",
    "        X = 1 - X\n",
    "        output = X * self.loss(pred, y)\n",
    "\n",
    "        if self.reduction == 'none':\n",
    "            output = output\n",
    "        elif self.reduction == 'mean':\n",
    "            output = output.sum() / X.sum()\n",
    "        elif self.reduction == 'sum':\n",
    "            output = output.sum()\n",
    "        else:\n",
    "            raise ValueError(f'{self.reduction} is not a valid value for reduction')\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def learn(\n",
    "    training_data,\n",
    "    test_data,\n",
    "    device,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    epoch=0,\n",
    "    epochs=5,\n",
    "    mdl_dir=None,\n",
    "    verbose=False,\n",
    "):\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    if verbose:\n",
    "        for X, y in test_dataloader:\n",
    "            print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "            print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "            break\n",
    "        print(f\"Using {device} device\")\n",
    "        print(model)\n",
    "\n",
    "    for t in range(epoch, epochs):\n",
    "        if verbose:\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer, verbose)\n",
    "        test(test_dataloader, model, loss_fn, verbose)\n",
    "        if mdl_dir:\n",
    "            mdl_path = join(mdl_dir, f\"model-{t+1}.pth\")\n",
    "            torch.save(model.state_dict(), mdl_path)\n",
    "            if verbose:\n",
    "                print(f\"Saved PyTorch Model State to {mdl_path}\")\n",
    "    if verbose:\n",
    "        print(\"Done!\")\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, verbose=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y, X)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0 and verbose:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn, verbose=True):\n",
    "    if verbose:\n",
    "        num_batches = len(dataloader)\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y, X).item()\n",
    "        test_loss /= num_batches\n",
    "        print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def get_noise(image, level=None):\n",
    "    _, height, width = image.shape\n",
    "    shape = (height, width)\n",
    "    \n",
    "    if level is None:\n",
    "        level = uniform(-1, 1)\n",
    "    \n",
    "    if res is None:\n",
    "        hght_res = choice([i for i in range(1, height + 1) if height % i == 0])\n",
    "        wdth_res = choice([i for i in range(1, width + 1) if width % i == 0])\n",
    "        res = (hght_res, wdth_res)\n",
    "    \n",
    "    black = torch.tensor(0.0, dtype=image.dtype).to(image.device)\n",
    "    white = torch.tensor(1.0, dtype=image.dtype).to(image.device)\n",
    "\n",
    "    noise = rand_perlin_2d(shape, res).to(image.dtype).to(image.device)\n",
    "    noise = torch.where(noise < level, black, white)\n",
    "    noise = torch.where(image == 0.0, white, noise)\n",
    "\n",
    "    return noise\n",
    "\n",
    "\n",
    "def get_observation(image, noise):\n",
    "    noise = 1 - noise\n",
    "    observation = image - noise\n",
    "    return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24feaab-7c4f-4212-b663-43afdfd177b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = DenoisingDataset('datasets/training', ptch_sz=70)\n",
    "test_data = DenoisingDataset('datasets/test', ptch_sz=70)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = DnCNN(depth=30).to(device)\n",
    "loss_fn = PepperWithLogitsLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters())\n",
    "learn(\n",
    "    training_data,\n",
    "    test_data,\n",
    "    device,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    epoch=0,\n",
    "    epochs=2000,\n",
    "    mdl_dir='models',\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c6e7d-ca4c-4a69-b252-1fe7c60d203d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
